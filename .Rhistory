boxplot(cv_acc5_rtimes, main = "KNN K = 7 cross validation accuracy", ylab = "Accuracy", xlab = "KNN")
## Answer
set.seed(3888)
cvK = 5  # number of CV folds
cv_acc5_rtimes = cv_acc5 = c()
n_sim = 45 ## number of repeats
X = t(golub[varid, ])
y = resp
n = nrow(X)
for (i in 1:n_sim) {
if (i %% 10 == 0) {
print(i)
}
cvSets = cvTools::cvFolds(n, cvK)  # permute all the data, into 5 folds
cv_acc_knn = c()
for (j in 1:cvK) {
test_id = cvSets$subsets[cvSets$which == j]
X_test = X[test_id, ]
X_train = X[-test_id, ]
y_test = y[test_id]
y_train = y[-test_id]
## KNN
fit5 = class::knn(train = X_train, test = X_test, cl = y_train, k = 7)
cv_acc5[j] = table(fit5, y_test) %>% diag() %>% sum() / length(y_test)
}
cv_acc5_rtimes <- append(cv_acc5_rtimes, mean(cv_acc5))
} ## end for
boxplot(cv_acc5_rtimes, main = "KNN K = 7 cross validation accuracy", ylab = "Accuracy", xlab = "KNN")
## Answer
set.seed(3888)
cvK = 5  # number of CV folds
X = t(golub[varid, ])
y = resp
n = nrow(X)
cvSets = cvTools::cvFolds(n, cvK)  # permute all the data, into 5 folds
fitres = factor()
true_y = c()
for (j in 1:cvK) {
test_id = cvSets$subsets[cvSets$which == j]
X_test = X[test_id, ]
X_train = X[-test_id, ]
y_test = y[test_id]
y_train = y[-test_id]
## KNN
fit5 = class::knn(train = X_train, test = X_test, cl = y_train, k = 10)
fitres = c(fitres, as.vector(fit5))
true_y = c(true_y, y_test)
}
ctab = table(fitres, true_y)
ctab
## Answer
imgList <- readRDS("data_2023/imgList.rds")
dim(imgList[[1]])
## Answer
imgList <- readRDS("data_2023/imgList.rds")
dim(imgList[[1]])
dim(imgList[[2]])
## Answer
xList <- lapply(imgList, function(x) x@.Data <- matrix(1, nrow(x), ncol(x)))
imgFeatures <- do.call(rbind, mapply(computeFeatures, x = xList, ref = imgList, MoreArgs = list(expandRef = NULL), SIMPLIFY = FALSE))
boxplot(imgFeatures, las = 2, cex.axis = 0.6)
## Answer
imgs_resized <- lapply(imgList, function(x) resize(x, dim = c(50, 50)))
## Answer
imgs_resized <- lapplylapply(imgList, resize, w = 50, h = 50)
## Answer
imgs_resized <- lapply(imgList, resize, w = 50, h = 50)
imgs_tiled <- tile(EBImage:::combine(imgs_resized))
## Answer
imgs_resized <- lapply(imgList, resize, w = 50, h = 50)
imgs_tiled <- tile(EBImage:::combine(imgs_resized))
## Answer
imgs_resized <- lapply(imgList, resize, w = 50, h = 50)
imgs_tiled <- tile(EBImage::combine(imgs_resized))
display(imgs_tiled)
## Answer
imgs_resized = lapply(imgList, resize, w = 50, h = 50)
imgs_tiles = tile(EBImage::combine(imgs_resized))
display(imgs_tiles)
shiny::runApp('C:/Users/User/OneDrive - The University of Sydney (Students)/USYD/Year 4 - Sem 1/DATA3888/2024/Project/Image_3/Shiny_Image')
runApp('C:/Users/User/OneDrive - The University of Sydney (Students)/USYD/Year 4 - Sem 1/DATA3888/2024/Project/Image_3/Shiny_Image')
runApp('C:/Users/User/OneDrive - The University of Sydney (Students)/USYD/Year 4 - Sem 1/DATA3888/2024/Project/Image_3/Shiny_Image')
runApp('C:/Users/User/OneDrive - The University of Sydney (Students)/USYD/Year 4 - Sem 1/DATA3888/2024/Project/Image_3/Shiny_Image')
results_nav_panel <- nav_panel(title = "Results", p("Results page content."))
runApp('C:/Users/User/OneDrive - The University of Sydney (Students)/USYD/Year 4 - Sem 1/DATA3888/2024/Project/Image_3/Shiny_Image')
runApp('C:/Users/User/OneDrive - The University of Sydney (Students)/USYD/Year 4 - Sem 1/DATA3888/2024/Project/Image_3/Shiny_Image')
# list all installed packages
installed_packages <- installed.packages()
# save the list to a text file, be careful to which directory you save this file
write.table(installed_packages[, c("Package", "Version")],
file = "installed_packages.txt", sep = "\t", quote = FALSE)
# list all installed packages
installed_packages <- installed.packages()
# save the list to a text file, be careful to which directory you save this file
write.table(installed_packages[, c("Package", "Version")],
file = "installed_packages.txt", sep = "\t", quote = FALSE)
install.packages("tuneR")
library(EBImage)
library(tidyverse)
library(pracma)
library(randomForest)
library(ggimage)
library(hash)
cluster_name = list.dirs("../data/Biotechnology/data_processed/cell_images", full.name = FALSE, recursive = FALSE)
cluster_img = hash()
cluster_cellID = hash()
cluster_files = hash()
file_path = "../data/Biotechnology/data_processed/cell_images/"
for (clusters in cluster_name) {
cluster_path = paste(file_path, clusters, sep = "")
cluster_files[[clusters]] = list.files(cluster_path,full.names = TRUE)
cluster_img[[clusters]] = sapply(cluster_files[[clusters]], readImage, simplify = FALSE)
cluster_cellID[[clusters]] = gsub(".*cell_|.png", "", cluster_files[[clusters]])
}
cell_boundaries_raw = read.csv("../data/Biotechnology/data_processed/cell_boundaries.csv.gz")
cell_centroids = cell_boundaries_raw %>%
group_by(cell_id) %>%
summarise(vertex_x = mean(vertex_x), vertex_y = mean(vertex_y))
flattened_clusters = c()
for (cl_n in cluster_name) {
for (cl in cluster_cellID[[cl_n]]) {
flattened_clusters = rbind(flattened_clusters,c(cl, cl_n))
}
}
flattened_clusters = data.frame(flattened_clusters)
colnames(flattened_clusters) = c("cell_id", "clusters")
flattened_clusters = flattened_clusters %>%
mutate(cell_id = as.numeric(cell_id))
merged_centroids = merge(cell_centroids, flattened_clusters)
ggplot(merged_centroids,
aes(x = vertex_x, y = vertex_y, colour = clusters)) +
geom_point() +
scale_y_reverse() +
theme(aspect.ratio = 1)
ggplot(cell_centroids, aes(x = vertex_x, y = vertex_y)) +
geom_point() +
scale_y_reverse() +
theme(aspect.ratio = 1)
get_inside = function(cellID, img, cell_boundaries, multiplier = 1) {
print(cellID)
cell_boundary = cell_boundaries %>%
filter(cell_id %in% cellID)
# rescale the boundary according to the pixels
pixels = dim(img)
cell_boundary$vertex_x_scaled <- 1+((cell_boundary$vertex_x - min(cell_boundary$vertex_x))/0.2125)
cell_boundary$vertex_y_scaled <- 1+((cell_boundary$vertex_y - min(cell_boundary$vertex_y))/0.2125)
# identify which pixels are inside or outside of the cell segment using inpolygon
pixel_locations = expand.grid(seq_len(nrow(img)), seq_len(ncol(img)))
pixels_inside = inpolygon(x = pixel_locations[,1],
y = pixel_locations[,2],
xp = cell_boundary$vertex_x_scaled,
yp = cell_boundary$vertex_y_scaled,
boundary = TRUE)
img_inside = img * multiplier
# img_inside = img
img_inside@.Data <- matrix(pixels_inside, nrow = nrow(img), ncol = ncol(img))
return(img_inside)
}
mask_resize = function(img, img_inside, w = 50, h = 50) {
img_mask = img * img_inside
# then, transform the masked image to the same number of pixels, 50x50
img_mask_resized = resize(img_mask, w, h)
return(img_mask_resized)
}
cluster_imgs_inside = hash()
cluster_imgs_resized = hash()
for (clusters in cluster_name) {
cluster_cell = cluster_cellID[[clusters]]
cluster_images = cluster_img[[clusters]]
cluster_inside = mapply(get_inside, cluster_cell, cluster_images, MoreArgs = list(cell_boundaries = cell_boundaries_raw), SIMPLIFY = FALSE)
cluster_masked_resized = mapply(mask_resize, cluster_images, cluster_inside, SIMPLIFY = FALSE)
cluster_imgs_inside[[clusters]] = cluster_inside
cluster_imgs_resized[[clusters]] = cluster_masked_resized
}
# Aldwin 7/5/24
# Merged the cluster_imgs_inside and cluster_imgs_resized into one file
save(cluster_imgs_inside, cluster_imgs_resized, file = "../data/cluster_imgs.Rdata")
# Save each cluster_imgs_inside and cluster_imgs_resized into separate files
save(cluster_imgs_inside, file = "../data/cluster_imgs_inside.Rdata")
save(cluster_imgs_resized, file = "../data/cluster_imgs_resized.Rdata")
library(shiny); runApp('C:/Users/User/OneDrive - The University of Sydney (Students)/USYD/Year 4 - Sem 1/DATA3888/2024/Project/Image_3/Draft/bia app.R')
library(shiny); runApp('C:/Users/User/OneDrive - The University of Sydney (Students)/USYD/Year 4 - Sem 1/DATA3888/2024/Project/Image_3/Shiny_Image/models.R')
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("EBImage")
remove.packages("fastmap")
remove.packages("stringi")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("EBImage")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("EBImage")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("EBImage", force = TRUE)
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("EBImage")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("EBImage")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager", force = T)
BiocManager::install("EBImage")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("EBImage", force = T)
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("EBImage", force = T)
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("EBImage", force = T)
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("EBImage")
# list all installed packages
installed_packages <- installed.packages()
# save the list to a text file, be careful to which directory you save this file
write.table(installed_packages[, c("Package", "Version")],
file = "installed_packages.txt", sep = "\t", quote = FALSE)
shiny::runApp('C:/Users/User/OneDrive - The University of Sydney (Students)/USYD/Year 4 - Sem 1/DATA3888/2024/Project/Image_3/Shiny_Image')
setwd("C:/Users/User/OneDrive - The University of Sydney (Students)/USYD/Winter Data Science Challenge/2024")
setwd("C:/Users/User/OneDrive - The University of Sydney (Students)/USYD/Winter Data Science Challenge/2024/Data_Science_Challenge_2024")
knitr::opts_chunk$set(echo = TRUE, Warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
library(readr)
df <- read_csv("data/life-expectancy.csv")
df
# Checking the structure of the data
str(le_df)
# Loading the data
le_df <- read_csv("data/life-expectancy.csv")
#le_df
# Checking the structure of the data
str(le_df)
# Loading the data
le_df <- read_csv("data/life-expectancy.csv")
head(le_df)
# Checking the structure of the data
str(le_df)
# Checking the summary of the data
summary(le_df)
# Loading the data
le_df <- read_csv("data/life-expectancy.csv")
head(le_df)
# Checking the structure of the data
str(le_df)
# Loading the data
le_df <- read_csv("data/life-expectancy.csv")
head(le_df)
knitr::opts_chunk$set(echo = TRUE, Warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
library(readr)
# Loading the data
le_df <- read_csv("data/life-expectancy.csv")
head(le_df)
# Checking the structure of the data
str(le_df)
# Checking the summary of the data
summary(le_df)
# Checking the missing values
missing_le_df <- le_df %>% summarise_all(funs(sum(is.na(.))))
missing_le_df
# Checking the missing values
missing_le_df <- le_df %>% summarise_all(~sum(is.na(.)))
missing_le_df
# Checking the missing values
missing_le_df <- le_df %>% summarise_all(~sum(is.na()))
# Checking the missing values
missing_le_df <- le_df %>% summarise_all(~sum(is.na(...)))
missing_le_df
# Checking the missing values
missing_le_df <- le_df %>% sum(is.na())
# Checking the missing values
missing_le_df <- le_df %>% sum(is.na(.))
# Checking the missing values
missing_le_df <- le_df %>% sum(is.na())
# Checking the missing values
missing_le_df <- le_df %>% which(colSums(is.na(.)) > 0)
# Checking the missing values
missing_le_df <- le_df %>% sum(colSums(is.na(.)) > 0)
# Checking the missing values
missing_le_df <- le_df %>% sum(is.na()
missing_le_df
# Checking the missing values
missing_le_df <- le_df %>% sum(is.na())
# Checking the missing values
missing_le_df <- le_df %>% sum(is.na(...))
# Checking the missing values
missing_le_df <- le_df %>% sum(is.na(le_df))
# Checking the missing values
missing_le_df <- le_df %>% sum(is.na(~))
# Checking the missing values
missing_le_df <- le_df %>% summarise_all(~sum(is.na(.)))
missing_le_df
# Checking the missing values
missing_le_df <- le_df %>% count(is.na(.))
missing_le_df
# Checking the missing values
missing_le_df <- le_df %>% count(is.na(.))
missing_le_df
# Checking the missing values
missing_le_df <- le_df %>% sapply(is.na) %>% colSums()
missing_le_df
# Checking the structure of the data
str(le_df)
# Checking the missing values
missing_le_df <- le_df %>% colSums(is.na(.))
# Checking the missing values
missing_le_df <- le_df %>% colSums(is.na(.))
# Checking the missing values
missing_le_df <- le_df %>% colSums(is.na())
# Checking the missing values
missing_le_df <- le_df %>% colSums(is.na(~))
# Checking the missing values
missing_le_df <- le_df %>% colSums(is.na(~)))
# Checking the missing values
missing_le_df <- le_df %>% colSums(is.na(~))
# Checking the missing values
missing_le_df <- le_df %>% colSums(is.na(...))
# Remove rows with missing values
le_df <- le_df %>% drop_na()
# Checking the dimensions of the data
dim(le_df)
# Remove rows with missing values
missing_le_df <- le_df %>% drop_na()
dim(missing_le_df)
library(tidyverse)
library(dplyr)
library(readr)
library(rmarkdown)
# Loading the data
le_df <- read_csv("data/life-expectancy.csv")
paged_table(le_df)
# Checking the dimensions of the data
dim(le_df)
# Checking the structure of the data
str(le_df)
# Remove rows with all missing values
missing_rows_le_df <- le_df %>%
filter_all(any_vars(!is.na(.))) %>%
nrow()
missing_rows_le_df
# Remove rows with all missing values
missing_rows_le_df <- le_df %>%
filter_all(any_vars(!is.na(.))) %>%
nrow()
dim(missing_rows_le_df)
# Remove rows with all missing values
missing_rows_le_df <- le_df %>%
filter_all(any_vars(!is.na(.))) %>%
nrow()
dim(missing_rows_le_df)
# Remove rows with all missing values
missing_rows_le_df <- le_df %>%
filter_all(any_vars(!is.na(.)))
dim(missing_rows_le_df)
# Checking the dimensions of the data
dim(le_df)
# Loading the data
le_df <- read_csv("data/life-expectancy.csv")
paged_table(le_df)
# Checking the dimensions of the data
dim(le_df)
# Checking the structure of the data
str(le_df)
# Remove rows with all missing values
missing_rows_le_df <- le_df %>%
filter_all(any_vars(!is.na(.)))
dim(missing_rows_le_df)
# Remove rows with all missing values
# missing_rows_le_df <- le_df %>%
#   filter_all(any_vars(!is.na(.)))
# dim(missing_rows_le_df)
# Remove rows with missing values
missing_rows_le_df <- le_df %>% drop_na()
dim(missing_rows_le_df)
# Remove rows with missing values
missing_vals_le_df <- le_df %>% drop_na()
dim(missing_rows_le_df)
knitr::opts_chunk$set(echo = TRUE, Warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
library(readr)
library(rmarkdown)
# Loading the data
le_df <- read_csv("data/life-expectancy.csv")
paged_table(le_df)
# Checking the dimensions of the data
dim(le_df)
# Checking the structure of the data
str(le_df)
# Checking the summary of the data
summary(le_df)
# Remove rows with missing values
missing_vals_le_df <- le_df %>% drop_na()
dim(missing_vals_le_df)
View(le_df)
continent_entities <- le_df %>% filter(is.na(Code)) %>%
select(Entity) %>% distinct()
continent_entities
knitr::opts_chunk$set(echo = TRUE, Warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
library(readr)
library(rmarkdown)
# Loading the data
le_df <- read_csv("data/life-expectancy.csv")
paged_table(le_df)
# Checking the dimensions of the data
dim(le_df)
# Checking the structure of the data
str(le_df)
# Checking the summary of the data
summary(le_df)
# Remove rows with missing values
missing_vals_le_df <- le_df %>% drop_na()
dim(missing_vals_le_df)
# Checking for entities with missing Code values
missing_entity_codes <- le_df %>% filter(is.na(Code)) %>%
select(Entity) %>% distinct()
missing_entity_codes
# Checking for entities with missing Code values
missing_entity_codes <- le_df %>% filter(is.na(Code)) %>%
select(Entity) %>% distinct()
missing_entity_codes
# create a world heatmap with the life expectancy of each country
le_df %>%
filter(Year == 2019) %>%
ggplot(aes(fill = `Life expectancy`)) +
geom_map(map = map_data("world"), aes(map_id = Entity), color = "black") +
expand_limits(x = map_data("world")$long, y = map_data("world")$lat) +
coord_map() +
scale_fill_viridis_c() +
theme_minimal() +
theme(legend.position = "bottom") +
labs(title = "Life Expectancy in 2019",
fill = "Life Expectancy",
x = "",
y = "")
# create a world heatmap with the life expectancy of each country
colnames(life_expectancy)[4] <- "Life_Expectancy"
# create a world heatmap with the life expectancy of each country
colnames(le_df)[4] <- "Life_Expectancy"
life_expectancy$Entity[le_df$Entity == "United States"] <- "USA"
# create a world heatmap with the life expectancy of each country
colnames(le_df)[4] <- "Life_Expectancy"
le_df$Entity[le_df$Entity == "United States"] <- "USA"
le_df$Entity[le_df$Entity == "Democratic Republic of Congo"] <- "Democratic Republic of the Congo"
le_df$Entity[le_df$Entity == "Congo"] <- "Republic of Congo"
le_df = subset(le_df, Year=='2020')
library(tidyverse)
library(magick)
world_map = subset(map_data("world"), region != "Antarctica")
ggplot() +
geom_polygon(data = world_map, aes(x = long, y = lat, group = group),
fill = "grey", alpha = 0.3) +
geom_map(map = world_map, data = life_expectancy_2020, aes(map_id=Entity, fill=Life_Expectancy)) +
scale_fill_gradient(low = "#cc4c02", high = "#fff7bc", name = "Life Expectancy") + theme_void() + coord_map()
# create a world heatmap with the life expectancy of each country
colnames(le_df)[4] <- "Life_Expectancy"
le_df$Entity[le_df$Entity == "United States"] <- "USA"
le_df$Entity[le_df$Entity == "Democratic Republic of Congo"] <- "Democratic Republic of the Congo"
le_df$Entity[le_df$Entity == "Congo"] <- "Republic of Congo"
life_expectancy_2020 = subset(le_df, Year=='2020')
library(tidyverse)
library(magick)
world_map = subset(map_data("world"), region != "Antarctica")
ggplot() +
geom_polygon(data = world_map, aes(x = long, y = lat, group = group),
fill = "grey", alpha = 0.3) +
geom_map(map = world_map, data = life_expectancy_2020, aes(map_id=Entity, fill=Life_Expectancy)) +
scale_fill_gradient(low = "#cc4c02", high = "#fff7bc", name = "Life Expectancy") + theme_void() + coord_map()
knitr::opts_chunk$set(echo = TRUE, Warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
library(readr)
library(rmarkdown)
# Loading the data
le_df <- read_csv("data/life-expectancy.csv")
paged_table(le_df)
# Checking the dimensions of the data
dim(le_df)
# Checking the structure of the data
str(le_df)
# Checking the summary of the data
summary(le_df)
# Remove rows with missing values
missing_vals_le_df <- le_df %>% drop_na()
dim(missing_vals_le_df)
# Checking for entities with missing Code values
missing_entity_codes <- le_df %>% filter(is.na(Code)) %>%
select(Entity) %>% distinct()
missing_entity_codes
# create a world heatmap with the life expectancy of each country
colnames(le_df)[4] <- "Life_Expectancy"
le_df$Entity[le_df$Entity == "United States"] <- "USA"
le_df$Entity[le_df$Entity == "Democratic Republic of Congo"] <- "Democratic Republic of the Congo"
le_df$Entity[le_df$Entity == "Congo"] <- "Republic of Congo"
life_expectancy_2020 = subset(le_df, Year=='2020')
library(tidyverse)
library(magick)
world_map = subset(map_data("world"), region != "Antarctica")
ggplot() +
geom_polygon(data = world_map, aes(x = long, y = lat, group = group),
fill = "grey", alpha = 0.3) +
geom_map(map = world_map, data = life_expectancy_2020, aes(map_id=Entity, fill=Life_Expectancy)) +
scale_fill_gradient(low = "#cc4c02", high = "#fff7bc", name = "Life Expectancy") + theme_void() + coord_fixed(1.2)
